{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Network Regression task - Bike sharing\n",
    "\n",
    "Bike sharing systems are new generation of traditional bike rentals where whole process from membership, rental and return has become automatic. Through these systems, a user is able to easily rent a bike from a particular position and return it at another place.\n",
    "\n",
    "The dataset contains the hourly count of rental bikes between years 2011 and 2012 in the Capital Bikeshare system (Wasington DC) with the corresponding weather and seasonal information.\n",
    "\n",
    "The goal of this task is to train a regressor to predict total counts of bike rentals based on the provided features for a given hour. \n",
    "\n",
    "## Data source\n",
    "[http://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset](http://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset)\n",
    "\n",
    "## Feature description\n",
    "* **dteday** - date time stamot\n",
    "* **season** - season (1: spring, 2: summer, 3: fall, 4: winter)\n",
    "* **yr** - year (0: 2011, 1: 2012)\n",
    "* **mnth** - month (1 to 12)\n",
    "* **hr** - hour (0 to 23)\n",
    "* **holiday** - 1 if the day is a holiday, else 0 (extracted from [holiday schedules](https://dchr.dc.gov/page/holiday-schedules))\n",
    "* **weekday** - day of the week (0 to 6)\n",
    "* **workingday** - is 1 if day is neither weekend nor holiday, else 0.\n",
    "* **weathersit** \n",
    "    * 1: Clear, Few clouds, Partly cloudy, Partly cloudy\n",
    "    * 2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist\n",
    "    * 3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds\n",
    "    * 4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog\n",
    "* **temp** - Normalized temperature in degrees of Celsius.\n",
    "* **atemp** - Normalized feeling temperature in degrees Celsius.\n",
    "* **hum** - Normalized relative humidity.\n",
    "* **windspeed** - Normalized wind speed.\n",
    "* **casual** - Count of casual users.\n",
    "* **registered** - Count of registered users.\n",
    "* **cnt** -  Count of total rental bikes including both casual and registered. This is the target value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       dteday  season  yr  mnth  hr  holiday  weekday  workingday  weathersit  \\\n",
       "0  2011-01-01       1   0     1   0        0        6           0           1   \n",
       "1  2011-01-01       1   0     1   1        0        6           0           1   \n",
       "2  2011-01-01       1   0     1   2        0        6           0           1   \n",
       "3  2011-01-01       1   0     1   3        0        6           0           1   \n",
       "4  2011-01-01       1   0     1   4        0        6           0           1   \n",
       "\n",
       "   temp   atemp   hum  windspeed  casual  registered  cnt  \n",
       "0  0.24  0.2879  0.81        0.0       3          13   16  \n",
       "1  0.22  0.2727  0.80        0.0       8          32   40  \n",
       "2  0.22  0.2727  0.80        0.0       5          27   32  \n",
       "3  0.24  0.2879  0.75        0.0       3          10   13  \n",
       "4  0.24  0.2879  0.75        0.0       0           1    1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('../data/bikes.csv', sep=',')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Neural Network Regressor\n",
    "\n",
    "Implement a recurrent neural network regressor. Sort the data by time stamp and deal with it as it was a time series. Be aware of using data from the past as test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       dteday  season  yr  mnth  hr  holiday  weekday  workingday  weathersit  \\\n",
       "0  2011-01-01       1   0     1   0        0        6           0           1   \n",
       "1  2011-01-01       1   0     1   1        0        6           0           1   \n",
       "2  2011-01-01       1   0     1   2        0        6           0           1   \n",
       "3  2011-01-01       1   0     1   3        0        6           0           1   \n",
       "4  2011-01-01       1   0     1   4        0        6           0           1   \n",
       "\n",
       "   temp   atemp   hum  windspeed  casual  registered  cnt  \n",
       "0  0.24  0.2879  0.81        0.0       3          13   16  \n",
       "1  0.22  0.2727  0.80        0.0       8          32   40  \n",
       "2  0.22  0.2727  0.80        0.0       5          27   32  \n",
       "3  0.24  0.2879  0.75        0.0       3          10   13  \n",
       "4  0.24  0.2879  0.75        0.0       0           1    1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sort_values(['dteday', 'hr'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add some features from the past\n",
    "\n",
    "Add the target feature from the previous hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "      <th>hist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0896</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       dteday  season  yr  mnth  hr  holiday  weekday  workingday  weathersit  \\\n",
       "1  2011-01-01       1   0     1   1        0        6           0           1   \n",
       "2  2011-01-01       1   0     1   2        0        6           0           1   \n",
       "3  2011-01-01       1   0     1   3        0        6           0           1   \n",
       "4  2011-01-01       1   0     1   4        0        6           0           1   \n",
       "5  2011-01-01       1   0     1   5        0        6           0           2   \n",
       "\n",
       "   temp   atemp   hum  windspeed  casual  registered  cnt  hist  \n",
       "1  0.22  0.2727  0.80     0.0000       8          32   40  16.0  \n",
       "2  0.22  0.2727  0.80     0.0000       5          27   32  40.0  \n",
       "3  0.24  0.2879  0.75     0.0000       3          10   13  32.0  \n",
       "4  0.24  0.2879  0.75     0.0000       0           1    1  13.0  \n",
       "5  0.24  0.2576  0.75     0.0896       0           1    1   1.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt = data['cnt']\n",
    "data['hist'] = cnt.shift(1)\n",
    "data = data[1:]\n",
    "\n",
    "X_all = data[['season', 'yr', 'mnth', 'holiday', 'weekday', 'workingday', 'weathersit','temp', 'atemp', 'hum', 'windspeed', 'hist']]\n",
    "y_all = data['cnt']\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequences\n",
    "\n",
    "Prepare train and test data sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "window = 10\n",
    "\n",
    "X_all = X_all.as_matrix()\n",
    "y_all = y_all.as_matrix()\n",
    "\n",
    "X_seq = []\n",
    "y_seq = []\n",
    "for i in range(window, len(X_all) + 1):\n",
    "    X_seq.append(X_all[i-window: i])\n",
    "    y_seq.append(y_all[i-1])\n",
    "\n",
    "X_seq = np.asarray(X_seq)\n",
    "y_seq = np.asarray(y_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into train and test data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: (15632, 10, 12)\n",
      "Test size: (1737, 10, 12)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_seq, \n",
    "    y_seq,\n",
    "    random_state=1,\n",
    "    test_size=0.1)\n",
    "\n",
    "#split_index = int(X_seq.shape[0]*0.9)\n",
    "#X_train = X_seq[:split_index,:,:]\n",
    "#X_test = X_seq[split_index:,:,:]\n",
    "#y_train = y_seq[:split_index]\n",
    "#y_test = y_seq[split_index:]\n",
    "\n",
    "print('Train size: {}'.format(X_train.shape))\n",
    "print('Test size: {}'.format(X_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardize the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "train_shape = X_train.shape\n",
    "test_shape = X_test.shape\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train.reshape(train_shape[0]*train_shape[1], train_shape[2]))\n",
    "X_train = scaler.transform(X_train.reshape(train_shape[0]*train_shape[1], train_shape[2])).reshape(train_shape)\n",
    "X_test = scaler.transform(X_test.reshape(test_shape[0]*test_shape[1], test_shape[2])).reshape(test_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a regressor\n",
    "Design and train a recurrent regression model with at least one [LSTM](https://keras.io/layers/recurrent/) layer. Use the [mean squared error](https://keras.io/losses/) loss function. Experiment with various architectures, [activation functions](https://keras.io/activations/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, LSTM\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(32, input_shape=(window, 12)))\n",
    "model.add(Dropout(0.15))\n",
    "model.add(Dense(32))\n",
    "model.add(Dense(1, activation='linear'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer='adam',\n",
    "              metrics=['mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15632 samples, validate on 1737 samples\n",
      "Epoch 1/100\n",
      "15632/15632 [==============================] - 1s 75us/step - loss: 59671.0811 - mean_absolute_error: 172.3212 - val_loss: 49453.1345 - val_mean_absolute_error: 153.6284\n",
      "Epoch 2/100\n",
      "15632/15632 [==============================] - 1s 61us/step - loss: 36516.0421 - mean_absolute_error: 134.0032 - val_loss: 32268.5678 - val_mean_absolute_error: 125.2075\n",
      "Epoch 3/100\n",
      "15632/15632 [==============================] - 1s 61us/step - loss: 24920.1800 - mean_absolute_error: 110.7849 - val_loss: 22784.0009 - val_mean_absolute_error: 104.0766\n",
      "Epoch 4/100\n",
      "15632/15632 [==============================] - 1s 62us/step - loss: 18198.8585 - mean_absolute_error: 94.9132 - val_loss: 17440.1276 - val_mean_absolute_error: 93.6941\n",
      "Epoch 5/100\n",
      "15632/15632 [==============================] - 1s 62us/step - loss: 14397.8912 - mean_absolute_error: 84.9766 - val_loss: 13909.4437 - val_mean_absolute_error: 81.1901\n",
      "Epoch 6/100\n",
      "15632/15632 [==============================] - 1s 62us/step - loss: 11626.5398 - mean_absolute_error: 75.8827 - val_loss: 11447.6236 - val_mean_absolute_error: 72.9908\n",
      "Epoch 7/100\n",
      "15632/15632 [==============================] - 1s 64us/step - loss: 9806.6907 - mean_absolute_error: 68.7774 - val_loss: 9875.4818 - val_mean_absolute_error: 67.6974\n",
      "Epoch 8/100\n",
      "15632/15632 [==============================] - 1s 61us/step - loss: 8460.1587 - mean_absolute_error: 62.9505 - val_loss: 8582.7614 - val_mean_absolute_error: 61.8763\n",
      "Epoch 9/100\n",
      "15632/15632 [==============================] - 1s 65us/step - loss: 7444.6899 - mean_absolute_error: 57.8688 - val_loss: 7155.0649 - val_mean_absolute_error: 55.4211\n",
      "Epoch 10/100\n",
      "15632/15632 [==============================] - 1s 61us/step - loss: 6211.4683 - mean_absolute_error: 52.3585 - val_loss: 6077.6838 - val_mean_absolute_error: 50.3613\n",
      "Epoch 11/100\n",
      "15632/15632 [==============================] - 1s 63us/step - loss: 5495.5000 - mean_absolute_error: 49.2177 - val_loss: 5337.5464 - val_mean_absolute_error: 47.2243\n",
      "Epoch 12/100\n",
      "15632/15632 [==============================] - 1s 62us/step - loss: 4941.5412 - mean_absolute_error: 46.8995 - val_loss: 4861.8960 - val_mean_absolute_error: 45.7024\n",
      "Epoch 13/100\n",
      "15632/15632 [==============================] - 1s 63us/step - loss: 4565.2224 - mean_absolute_error: 45.2516 - val_loss: 4262.8490 - val_mean_absolute_error: 43.2287\n",
      "Epoch 14/100\n",
      "15632/15632 [==============================] - 1s 63us/step - loss: 4102.0833 - mean_absolute_error: 43.2256 - val_loss: 3801.1385 - val_mean_absolute_error: 40.5636\n",
      "Epoch 15/100\n",
      "15632/15632 [==============================] - 1s 62us/step - loss: 3751.4318 - mean_absolute_error: 41.8793 - val_loss: 3360.0144 - val_mean_absolute_error: 38.8257\n",
      "Epoch 16/100\n",
      "15632/15632 [==============================] - 1s 62us/step - loss: 3433.7474 - mean_absolute_error: 40.2169 - val_loss: 3067.0877 - val_mean_absolute_error: 37.4684\n",
      "Epoch 17/100\n",
      "15632/15632 [==============================] - 1s 66us/step - loss: 3196.1560 - mean_absolute_error: 38.9772 - val_loss: 2733.7137 - val_mean_absolute_error: 35.3652\n",
      "Epoch 18/100\n",
      "15632/15632 [==============================] - 1s 63us/step - loss: 2961.4172 - mean_absolute_error: 37.7407 - val_loss: 2566.7841 - val_mean_absolute_error: 34.4768\n",
      "Epoch 19/100\n",
      "15632/15632 [==============================] - 1s 65us/step - loss: 2833.1150 - mean_absolute_error: 37.0296 - val_loss: 2393.1867 - val_mean_absolute_error: 33.7704\n",
      "Epoch 20/100\n",
      "15632/15632 [==============================] - 1s 62us/step - loss: 2737.2217 - mean_absolute_error: 36.1236 - val_loss: 2316.3360 - val_mean_absolute_error: 32.8804\n",
      "Epoch 21/100\n",
      "15632/15632 [==============================] - 1s 64us/step - loss: 2595.3531 - mean_absolute_error: 35.2950 - val_loss: 2382.2408 - val_mean_absolute_error: 32.5352\n",
      "Epoch 22/100\n",
      "15632/15632 [==============================] - 1s 66us/step - loss: 2485.2386 - mean_absolute_error: 34.6344 - val_loss: 2110.4384 - val_mean_absolute_error: 31.7514\n",
      "Epoch 23/100\n",
      "15632/15632 [==============================] - 1s 64us/step - loss: 2437.4422 - mean_absolute_error: 34.2127 - val_loss: 2083.7451 - val_mean_absolute_error: 31.3680\n",
      "Epoch 24/100\n",
      "15632/15632 [==============================] - 1s 74us/step - loss: 2346.6614 - mean_absolute_error: 33.6654 - val_loss: 1958.0593 - val_mean_absolute_error: 30.4230\n",
      "Epoch 25/100\n",
      "15632/15632 [==============================] - 1s 80us/step - loss: 2292.3845 - mean_absolute_error: 33.1364 - val_loss: 1949.7450 - val_mean_absolute_error: 30.0984\n",
      "Epoch 26/100\n",
      "15632/15632 [==============================] - 1s 64us/step - loss: 2199.8347 - mean_absolute_error: 32.5607 - val_loss: 1882.9621 - val_mean_absolute_error: 29.5389\n",
      "Epoch 27/100\n",
      "15632/15632 [==============================] - 1s 63us/step - loss: 2206.8227 - mean_absolute_error: 32.5023 - val_loss: 1866.8959 - val_mean_absolute_error: 29.4485\n",
      "Epoch 28/100\n",
      "15632/15632 [==============================] - 1s 65us/step - loss: 2133.4134 - mean_absolute_error: 31.8240 - val_loss: 1780.8574 - val_mean_absolute_error: 28.9606\n",
      "Epoch 29/100\n",
      "15632/15632 [==============================] - 1s 63us/step - loss: 2080.1333 - mean_absolute_error: 31.4369 - val_loss: 1824.9757 - val_mean_absolute_error: 28.8033\n",
      "Epoch 30/100\n",
      "15632/15632 [==============================] - 1s 63us/step - loss: 2068.3545 - mean_absolute_error: 31.6124 - val_loss: 1694.6010 - val_mean_absolute_error: 28.1981\n",
      "Epoch 31/100\n",
      "15632/15632 [==============================] - 1s 65us/step - loss: 2054.8244 - mean_absolute_error: 31.3216 - val_loss: 1734.5585 - val_mean_absolute_error: 28.2064\n",
      "Epoch 32/100\n",
      "15632/15632 [==============================] - 1s 67us/step - loss: 2023.1587 - mean_absolute_error: 31.0705 - val_loss: 1739.1254 - val_mean_absolute_error: 28.2355\n",
      "Epoch 33/100\n",
      "15632/15632 [==============================] - 1s 64us/step - loss: 1992.6933 - mean_absolute_error: 30.8781 - val_loss: 1686.1021 - val_mean_absolute_error: 28.4483\n",
      "Epoch 34/100\n",
      "15632/15632 [==============================] - 1s 66us/step - loss: 1949.5402 - mean_absolute_error: 30.4129 - val_loss: 1675.8444 - val_mean_absolute_error: 28.0341\n",
      "Epoch 35/100\n",
      "15632/15632 [==============================] - 1s 65us/step - loss: 1923.6470 - mean_absolute_error: 30.2310 - val_loss: 1590.3588 - val_mean_absolute_error: 27.1314\n",
      "Epoch 36/100\n",
      "15632/15632 [==============================] - 1s 66us/step - loss: 1912.9818 - mean_absolute_error: 30.3181 - val_loss: 1602.9490 - val_mean_absolute_error: 27.1051\n",
      "Epoch 37/100\n",
      "15632/15632 [==============================] - 1s 64us/step - loss: 1881.2378 - mean_absolute_error: 29.9916 - val_loss: 1559.5503 - val_mean_absolute_error: 26.7533\n",
      "Epoch 38/100\n",
      "15632/15632 [==============================] - 1s 65us/step - loss: 1906.6430 - mean_absolute_error: 30.1124 - val_loss: 1689.9221 - val_mean_absolute_error: 27.3923\n",
      "Epoch 39/100\n",
      "15632/15632 [==============================] - 1s 63us/step - loss: 1880.2290 - mean_absolute_error: 30.0178 - val_loss: 1530.7258 - val_mean_absolute_error: 26.5136\n",
      "Epoch 40/100\n",
      "15632/15632 [==============================] - 1s 68us/step - loss: 1827.3542 - mean_absolute_error: 29.4547 - val_loss: 1546.7126 - val_mean_absolute_error: 26.6186\n",
      "Epoch 41/100\n",
      "15632/15632 [==============================] - 1s 69us/step - loss: 1799.3066 - mean_absolute_error: 29.2036 - val_loss: 1525.5047 - val_mean_absolute_error: 26.5552\n",
      "Epoch 42/100\n",
      "15632/15632 [==============================] - 1s 66us/step - loss: 1787.9658 - mean_absolute_error: 29.2404 - val_loss: 1552.9465 - val_mean_absolute_error: 26.3696\n",
      "Epoch 43/100\n",
      "15632/15632 [==============================] - 1s 65us/step - loss: 1736.0376 - mean_absolute_error: 28.9172 - val_loss: 1506.3843 - val_mean_absolute_error: 26.0486\n",
      "Epoch 44/100\n",
      "15632/15632 [==============================] - 1s 71us/step - loss: 1759.7570 - mean_absolute_error: 29.0150 - val_loss: 1460.2614 - val_mean_absolute_error: 25.7716\n",
      "Epoch 45/100\n",
      "15632/15632 [==============================] - 1s 66us/step - loss: 1741.8475 - mean_absolute_error: 28.7145 - val_loss: 1476.6407 - val_mean_absolute_error: 26.0728\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15632/15632 [==============================] - 1s 66us/step - loss: 1732.0040 - mean_absolute_error: 28.5208 - val_loss: 1464.4539 - val_mean_absolute_error: 26.0387\n",
      "Epoch 47/100\n",
      "15632/15632 [==============================] - 1s 64us/step - loss: 1744.3963 - mean_absolute_error: 28.6933 - val_loss: 1414.0400 - val_mean_absolute_error: 25.5285\n",
      "Epoch 48/100\n",
      "15632/15632 [==============================] - 1s 60us/step - loss: 1704.8966 - mean_absolute_error: 28.4127 - val_loss: 1409.3531 - val_mean_absolute_error: 25.3057\n",
      "Epoch 49/100\n",
      "15632/15632 [==============================] - 1s 60us/step - loss: 1659.2827 - mean_absolute_error: 28.1001 - val_loss: 1436.9547 - val_mean_absolute_error: 25.2996\n",
      "Epoch 50/100\n",
      "15632/15632 [==============================] - 1s 61us/step - loss: 1640.3980 - mean_absolute_error: 27.9588 - val_loss: 1396.5750 - val_mean_absolute_error: 25.2587\n",
      "Epoch 51/100\n",
      "15632/15632 [==============================] - 1s 68us/step - loss: 1673.9763 - mean_absolute_error: 28.0696 - val_loss: 1440.2793 - val_mean_absolute_error: 25.7860\n",
      "Epoch 52/100\n",
      "15632/15632 [==============================] - 1s 68us/step - loss: 1675.0334 - mean_absolute_error: 28.0619 - val_loss: 1449.1347 - val_mean_absolute_error: 25.7433\n",
      "Epoch 53/100\n",
      "15632/15632 [==============================] - 1s 78us/step - loss: 1669.8141 - mean_absolute_error: 27.9363 - val_loss: 1392.2122 - val_mean_absolute_error: 25.0566\n",
      "Epoch 54/100\n",
      "15632/15632 [==============================] - 1s 76us/step - loss: 1638.2280 - mean_absolute_error: 27.8222 - val_loss: 1378.3299 - val_mean_absolute_error: 25.0290\n",
      "Epoch 55/100\n",
      "15632/15632 [==============================] - 1s 80us/step - loss: 1607.9955 - mean_absolute_error: 27.4858 - val_loss: 1375.5419 - val_mean_absolute_error: 24.9592\n",
      "Epoch 56/100\n",
      "15632/15632 [==============================] - 1s 67us/step - loss: 1618.8658 - mean_absolute_error: 27.6619 - val_loss: 1454.5846 - val_mean_absolute_error: 25.4027\n",
      "Epoch 57/100\n",
      "15632/15632 [==============================] - 1s 63us/step - loss: 1615.0602 - mean_absolute_error: 27.6327 - val_loss: 1386.2167 - val_mean_absolute_error: 24.9407\n",
      "Epoch 58/100\n",
      "15632/15632 [==============================] - 1s 71us/step - loss: 1579.4441 - mean_absolute_error: 27.4826 - val_loss: 1357.0572 - val_mean_absolute_error: 24.6737\n",
      "Epoch 59/100\n",
      "15632/15632 [==============================] - 1s 74us/step - loss: 1586.7763 - mean_absolute_error: 27.3850 - val_loss: 1345.3342 - val_mean_absolute_error: 24.7155\n",
      "Epoch 60/100\n",
      "15632/15632 [==============================] - 1s 77us/step - loss: 1568.2102 - mean_absolute_error: 27.2332 - val_loss: 1360.3287 - val_mean_absolute_error: 24.8679\n",
      "Epoch 61/100\n",
      "15632/15632 [==============================] - 1s 70us/step - loss: 1568.5416 - mean_absolute_error: 27.3099 - val_loss: 1313.9641 - val_mean_absolute_error: 24.4802\n",
      "Epoch 62/100\n",
      "15632/15632 [==============================] - 1s 64us/step - loss: 1542.8705 - mean_absolute_error: 27.1458 - val_loss: 1285.6938 - val_mean_absolute_error: 23.9382\n",
      "Epoch 63/100\n",
      "15632/15632 [==============================] - 1s 68us/step - loss: 1533.5306 - mean_absolute_error: 26.7993 - val_loss: 1335.1767 - val_mean_absolute_error: 24.4847\n",
      "Epoch 64/100\n",
      "15632/15632 [==============================] - 1s 65us/step - loss: 1516.8071 - mean_absolute_error: 26.8776 - val_loss: 1340.4429 - val_mean_absolute_error: 24.3585\n",
      "Epoch 65/100\n",
      "15632/15632 [==============================] - 1s 76us/step - loss: 1502.4040 - mean_absolute_error: 26.7677 - val_loss: 1305.9609 - val_mean_absolute_error: 24.3550\n",
      "Epoch 66/100\n",
      "15632/15632 [==============================] - 1s 65us/step - loss: 1545.7044 - mean_absolute_error: 27.0999 - val_loss: 1320.2947 - val_mean_absolute_error: 24.2952\n",
      "Epoch 67/100\n",
      "15632/15632 [==============================] - 1s 75us/step - loss: 1536.6180 - mean_absolute_error: 26.9589 - val_loss: 1337.5121 - val_mean_absolute_error: 24.4826\n",
      "Epoch 68/100\n",
      "15632/15632 [==============================] - 1s 79us/step - loss: 1477.8781 - mean_absolute_error: 26.5794 - val_loss: 1293.7072 - val_mean_absolute_error: 24.1209\n",
      "Epoch 69/100\n",
      "15632/15632 [==============================] - 1s 78us/step - loss: 1550.7526 - mean_absolute_error: 26.9731 - val_loss: 1301.1010 - val_mean_absolute_error: 24.5023\n",
      "Epoch 70/100\n",
      "15632/15632 [==============================] - 1s 70us/step - loss: 1494.0566 - mean_absolute_error: 26.6686 - val_loss: 1255.1412 - val_mean_absolute_error: 23.8330\n",
      "Epoch 71/100\n",
      "15632/15632 [==============================] - 1s 67us/step - loss: 1480.9753 - mean_absolute_error: 26.4896 - val_loss: 1306.5480 - val_mean_absolute_error: 24.3196\n",
      "Epoch 72/100\n",
      "15632/15632 [==============================] - 1s 61us/step - loss: 1513.4184 - mean_absolute_error: 26.7072 - val_loss: 1228.1338 - val_mean_absolute_error: 23.5587\n",
      "Epoch 73/100\n",
      "15632/15632 [==============================] - 1s 60us/step - loss: 1463.5100 - mean_absolute_error: 26.2228 - val_loss: 1249.6868 - val_mean_absolute_error: 23.7623\n",
      "Epoch 74/100\n",
      "15632/15632 [==============================] - 1s 59us/step - loss: 1465.4481 - mean_absolute_error: 26.2042 - val_loss: 1277.1267 - val_mean_absolute_error: 24.1268\n",
      "Epoch 75/100\n",
      "15632/15632 [==============================] - 1s 62us/step - loss: 1461.4970 - mean_absolute_error: 26.4504 - val_loss: 1281.1827 - val_mean_absolute_error: 24.0241\n",
      "Epoch 76/100\n",
      "15632/15632 [==============================] - 1s 58us/step - loss: 1437.3999 - mean_absolute_error: 26.1531 - val_loss: 1251.0301 - val_mean_absolute_error: 23.7454\n",
      "Epoch 77/100\n",
      "15632/15632 [==============================] - 1s 56us/step - loss: 1456.3458 - mean_absolute_error: 26.2157 - val_loss: 1247.2119 - val_mean_absolute_error: 23.7920\n",
      "Epoch 78/100\n",
      "15632/15632 [==============================] - 1s 58us/step - loss: 1425.9105 - mean_absolute_error: 26.0269 - val_loss: 1245.5130 - val_mean_absolute_error: 23.6041\n",
      "Epoch 79/100\n",
      "15632/15632 [==============================] - 1s 58us/step - loss: 1436.3804 - mean_absolute_error: 26.0320 - val_loss: 1272.8569 - val_mean_absolute_error: 23.9353\n",
      "Epoch 80/100\n",
      "15632/15632 [==============================] - 1s 56us/step - loss: 1433.7788 - mean_absolute_error: 26.0851 - val_loss: 1224.2934 - val_mean_absolute_error: 23.7258\n",
      "Epoch 81/100\n",
      "15632/15632 [==============================] - 1s 94us/step - loss: 1455.3804 - mean_absolute_error: 26.1354 - val_loss: 1230.2139 - val_mean_absolute_error: 23.7600\n",
      "Epoch 82/100\n",
      "15632/15632 [==============================] - 1s 58us/step - loss: 1376.0504 - mean_absolute_error: 25.7287 - val_loss: 1224.2444 - val_mean_absolute_error: 23.7708\n",
      "Epoch 83/100\n",
      "15632/15632 [==============================] - 1s 61us/step - loss: 1446.8219 - mean_absolute_error: 26.0668 - val_loss: 1224.0766 - val_mean_absolute_error: 23.5008\n",
      "Epoch 84/100\n",
      "15632/15632 [==============================] - 1s 57us/step - loss: 1387.6777 - mean_absolute_error: 25.7118 - val_loss: 1248.9730 - val_mean_absolute_error: 23.5902\n",
      "Epoch 85/100\n",
      "15632/15632 [==============================] - 1s 56us/step - loss: 1395.4402 - mean_absolute_error: 25.8399 - val_loss: 1223.8030 - val_mean_absolute_error: 23.5505\n",
      "Epoch 86/100\n",
      "15632/15632 [==============================] - 1s 58us/step - loss: 1409.5027 - mean_absolute_error: 25.7671 - val_loss: 1191.4649 - val_mean_absolute_error: 23.3925\n",
      "Epoch 87/100\n",
      "15632/15632 [==============================] - 1s 74us/step - loss: 1394.4737 - mean_absolute_error: 25.7531 - val_loss: 1212.8683 - val_mean_absolute_error: 23.4600\n",
      "Epoch 88/100\n",
      "15632/15632 [==============================] - 1s 71us/step - loss: 1390.7648 - mean_absolute_error: 25.8522 - val_loss: 1203.1640 - val_mean_absolute_error: 23.3768\n",
      "Epoch 89/100\n",
      "15632/15632 [==============================] - 1s 65us/step - loss: 1375.6475 - mean_absolute_error: 25.6364 - val_loss: 1252.5638 - val_mean_absolute_error: 23.8134\n",
      "Epoch 90/100\n",
      "15632/15632 [==============================] - 1s 72us/step - loss: 1384.5748 - mean_absolute_error: 25.6760 - val_loss: 1228.8740 - val_mean_absolute_error: 23.5393\n",
      "Epoch 91/100\n",
      "15632/15632 [==============================] - 1s 67us/step - loss: 1372.6265 - mean_absolute_error: 25.6291 - val_loss: 1243.9647 - val_mean_absolute_error: 23.5751\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/100\n",
      "15632/15632 [==============================] - 1s 58us/step - loss: 1395.6780 - mean_absolute_error: 25.6362 - val_loss: 1244.5065 - val_mean_absolute_error: 23.6303\n",
      "Epoch 93/100\n",
      "15632/15632 [==============================] - 1s 59us/step - loss: 1339.1925 - mean_absolute_error: 25.2352 - val_loss: 1205.8985 - val_mean_absolute_error: 23.5869\n",
      "Epoch 94/100\n",
      "15632/15632 [==============================] - 1s 60us/step - loss: 1384.7510 - mean_absolute_error: 25.6884 - val_loss: 1225.3174 - val_mean_absolute_error: 23.4867\n",
      "Epoch 95/100\n",
      "15632/15632 [==============================] - 1s 60us/step - loss: 1329.4912 - mean_absolute_error: 25.0524 - val_loss: 1212.7804 - val_mean_absolute_error: 23.3923\n",
      "Epoch 96/100\n",
      "15632/15632 [==============================] - 1s 59us/step - loss: 1343.6306 - mean_absolute_error: 25.4282 - val_loss: 1257.8317 - val_mean_absolute_error: 23.8950\n",
      "Epoch 97/100\n",
      "15632/15632 [==============================] - 1s 60us/step - loss: 1367.7871 - mean_absolute_error: 25.5606 - val_loss: 1186.7098 - val_mean_absolute_error: 23.2085\n",
      "Epoch 98/100\n",
      "15632/15632 [==============================] - 1s 59us/step - loss: 1337.2821 - mean_absolute_error: 25.3450 - val_loss: 1193.8329 - val_mean_absolute_error: 23.2497\n",
      "Epoch 99/100\n",
      "15632/15632 [==============================] - 1s 59us/step - loss: 1304.1963 - mean_absolute_error: 25.0501 - val_loss: 1166.3387 - val_mean_absolute_error: 22.7485\n",
      "Epoch 100/100\n",
      "15632/15632 [==============================] - 1s 55us/step - loss: 1318.5049 - mean_absolute_error: 25.2067 - val_loss: 1150.5484 - val_mean_absolute_error: 22.8960\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f65e919ab00>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train,\n",
    "          batch_size = 128, epochs = 100, verbose=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the models\n",
    "\n",
    "Measure mean squared error and mean absolute error evaluation metrics on both train and test data sets. Compute the mean and standard deviation of the target values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test mean: 196.9222797927461, std: 187.62398319999474\n",
      "Test Root mean squared error: 33.92\n",
      "Test Mean absolute error: 22.90\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print (\"Test mean: {}, std: {}\".format(np.mean(y_test), np.std(y_test)))\n",
    "print(\"Test Root mean squared error: {:.2f}\".format(np.sqrt(mean_squared_error(y_test, y_pred))))\n",
    "print(\"Test Mean absolute error: {:.2f}\".format(mean_absolute_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Root mean squared error: 30.13\n",
      "Train Mean absolute error: 20.65\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_train)\n",
    "print(\"Train Root mean squared error: %.2f\"\n",
    "      % np.sqrt(mean_squared_error(y_train, y_pred)))\n",
    "print(\"Train Mean absolute error: %.2f\"\n",
    "      % mean_absolute_error(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
