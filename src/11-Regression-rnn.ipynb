{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Network Regression task - Bike sharing\n",
    "\n",
    "Bike sharing systems are new generation of traditional bike rentals where whole process from membership, rental and return has become automatic. Through these systems, a user is able to easily rent a bike from a particular position and return it at another place.\n",
    "\n",
    "The dataset contains the hourly count of rental bikes between years 2011 and 2012 in the Capital Bikeshare system (Wasington DC) with the corresponding weather and seasonal information.\n",
    "\n",
    "The goal of this task is to train a regressor to predict total counts of bike rentals based on the provided features for a given hour. \n",
    "\n",
    "## Data source\n",
    "[http://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset](http://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset)\n",
    "\n",
    "## Feature description\n",
    "* **dteday** - date time stamot\n",
    "* **season** - season (1: spring, 2: summer, 3: fall, 4: winter)\n",
    "* **yr** - year (0: 2011, 1: 2012)\n",
    "* **mnth** - month (1 to 12)\n",
    "* **hr** - hour (0 to 23)\n",
    "* **holiday** - 1 if the day is a holiday, else 0 (extracted from [holiday schedules](https://dchr.dc.gov/page/holiday-schedules))\n",
    "* **weekday** - day of the week (0 to 6)\n",
    "* **workingday** - is 1 if day is neither weekend nor holiday, else 0.\n",
    "* **weathersit** \n",
    "    * 1: Clear, Few clouds, Partly cloudy, Partly cloudy\n",
    "    * 2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist\n",
    "    * 3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds\n",
    "    * 4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog\n",
    "* **temp** - Normalized temperature in degrees of Celsius.\n",
    "* **atemp** - Normalized feeling temperature in degrees Celsius.\n",
    "* **hum** - Normalized relative humidity.\n",
    "* **windspeed** - Normalized wind speed.\n",
    "* **casual** - Count of casual users.\n",
    "* **registered** - Count of registered users.\n",
    "* **cnt** -  Count of total rental bikes including both casual and registered. This is the target value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       dteday  season  yr  mnth  hr  holiday  weekday  workingday  weathersit  \\\n",
       "0  2011-01-01       1   0     1   0        0        6           0           1   \n",
       "1  2011-01-01       1   0     1   1        0        6           0           1   \n",
       "2  2011-01-01       1   0     1   2        0        6           0           1   \n",
       "3  2011-01-01       1   0     1   3        0        6           0           1   \n",
       "4  2011-01-01       1   0     1   4        0        6           0           1   \n",
       "\n",
       "   temp   atemp   hum  windspeed  casual  registered  cnt  \n",
       "0  0.24  0.2879  0.81        0.0       3          13   16  \n",
       "1  0.22  0.2727  0.80        0.0       8          32   40  \n",
       "2  0.22  0.2727  0.80        0.0       5          27   32  \n",
       "3  0.24  0.2879  0.75        0.0       3          10   13  \n",
       "4  0.24  0.2879  0.75        0.0       0           1    1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('../data/bikes.csv', sep=',')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Neural Network Regressor\n",
    "\n",
    "Implement a recurrent neural network regressor. Sort the data by time stamp and deal with it as it was a time series. Be aware of using data from the past as test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       dteday  season  yr  mnth  hr  holiday  weekday  workingday  weathersit  \\\n",
       "0  2011-01-01       1   0     1   0        0        6           0           1   \n",
       "1  2011-01-01       1   0     1   1        0        6           0           1   \n",
       "2  2011-01-01       1   0     1   2        0        6           0           1   \n",
       "3  2011-01-01       1   0     1   3        0        6           0           1   \n",
       "4  2011-01-01       1   0     1   4        0        6           0           1   \n",
       "\n",
       "   temp   atemp   hum  windspeed  casual  registered  cnt  \n",
       "0  0.24  0.2879  0.81        0.0       3          13   16  \n",
       "1  0.22  0.2727  0.80        0.0       8          32   40  \n",
       "2  0.22  0.2727  0.80        0.0       5          27   32  \n",
       "3  0.24  0.2879  0.75        0.0       3          10   13  \n",
       "4  0.24  0.2879  0.75        0.0       0           1    1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sort_values(['dteday', 'hr'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add some features from the past\n",
    "\n",
    "Add the target feature from the previous hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "      <th>hist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0896</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       dteday  season  yr  mnth  hr  holiday  weekday  workingday  weathersit  \\\n",
       "1  2011-01-01       1   0     1   1        0        6           0           1   \n",
       "2  2011-01-01       1   0     1   2        0        6           0           1   \n",
       "3  2011-01-01       1   0     1   3        0        6           0           1   \n",
       "4  2011-01-01       1   0     1   4        0        6           0           1   \n",
       "5  2011-01-01       1   0     1   5        0        6           0           2   \n",
       "\n",
       "   temp   atemp   hum  windspeed  casual  registered  cnt  hist  \n",
       "1  0.22  0.2727  0.80     0.0000       8          32   40  16.0  \n",
       "2  0.22  0.2727  0.80     0.0000       5          27   32  40.0  \n",
       "3  0.24  0.2879  0.75     0.0000       3          10   13  32.0  \n",
       "4  0.24  0.2879  0.75     0.0000       0           1    1  13.0  \n",
       "5  0.24  0.2576  0.75     0.0896       0           1    1   1.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt = data['cnt']\n",
    "data['hist'] = cnt.shift(1)\n",
    "data = data[1:]\n",
    "\n",
    "X_all = data[['season', 'yr', 'mnth', 'hr', 'holiday', 'weekday', 'workingday', 'weathersit','temp', 'atemp', 'hum', 'windspeed', 'hist']]\n",
    "y_all = data['cnt']\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequences\n",
    "\n",
    "Prepare train and test data sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "window = 10\n",
    "\n",
    "X_all = X_all.as_matrix()\n",
    "y_all = y_all.as_matrix()\n",
    "\n",
    "X_seq = []\n",
    "y_seq = []\n",
    "for i in range(window, len(X_all) + 1):\n",
    "    X_seq.append(X_all[i-window: i])\n",
    "    y_seq.append(y_all[i-1])\n",
    "\n",
    "X_seq = np.asarray(X_seq)\n",
    "y_seq = np.asarray(y_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into train and test data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: (15632, 10, 13)\n",
      "Test size: (1737, 10, 13)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_seq, \n",
    "    y_seq,\n",
    "    random_state=1,\n",
    "    test_size=0.1)\n",
    "\n",
    "#split_index = int(X_seq.shape[0]*0.9)\n",
    "#X_train = X_seq[:split_index,:,:]\n",
    "#X_test = X_seq[split_index:,:,:]\n",
    "#y_train = y_seq[:split_index]\n",
    "#y_test = y_seq[split_index:]\n",
    "\n",
    "print('Train size: {}'.format(X_train.shape))\n",
    "print('Test size: {}'.format(X_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardize the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "train_shape = X_train.shape\n",
    "test_shape = X_test.shape\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train.reshape(train_shape[0]*train_shape[1], train_shape[2]))\n",
    "X_train = scaler.transform(X_train.reshape(train_shape[0]*train_shape[1], train_shape[2])).reshape(train_shape)\n",
    "X_test = scaler.transform(X_test.reshape(test_shape[0]*test_shape[1], test_shape[2])).reshape(test_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a regressor\n",
    "Design and train a recurrent regression model with at least one [LSTM](https://keras.io/layers/recurrent/) layer. Use the [mean squared error](https://keras.io/losses/) loss function. Experiment with various architectures, [activation functions](https://keras.io/activations/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, LSTM\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(32, input_shape=(window, 13)))\n",
    "model.add(Dropout(0.15))\n",
    "model.add(Dense(32))\n",
    "model.add(Dense(1, activation='linear'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer='adam',\n",
    "              metrics=['mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15632 samples, validate on 1737 samples\n",
      "Epoch 1/100\n",
      "15632/15632 [==============================] - 1s 80us/step - loss: 60402.4328 - mean_absolute_error: 173.3730 - val_loss: 50387.8350 - val_mean_absolute_error: 154.4258\n",
      "Epoch 2/100\n",
      "15632/15632 [==============================] - 1s 64us/step - loss: 34322.3648 - mean_absolute_error: 119.0098 - val_loss: 27290.4444 - val_mean_absolute_error: 100.9606\n",
      "Epoch 3/100\n",
      "15632/15632 [==============================] - 1s 61us/step - loss: 19179.0151 - mean_absolute_error: 84.9146 - val_loss: 16880.1100 - val_mean_absolute_error: 79.7872\n",
      "Epoch 4/100\n",
      "15632/15632 [==============================] - 1s 58us/step - loss: 13332.6648 - mean_absolute_error: 71.9040 - val_loss: 12734.2302 - val_mean_absolute_error: 69.6845\n",
      "Epoch 5/100\n",
      "15632/15632 [==============================] - 1s 58us/step - loss: 10418.9625 - mean_absolute_error: 63.3709 - val_loss: 10002.1575 - val_mean_absolute_error: 60.4014\n",
      "Epoch 6/100\n",
      "15632/15632 [==============================] - 1s 59us/step - loss: 7775.8818 - mean_absolute_error: 54.3060 - val_loss: 6170.6060 - val_mean_absolute_error: 47.6712\n",
      "Epoch 7/100\n",
      "15632/15632 [==============================] - 1s 63us/step - loss: 4969.2433 - mean_absolute_error: 43.7676 - val_loss: 4034.2689 - val_mean_absolute_error: 38.2137\n",
      "Epoch 8/100\n",
      "15632/15632 [==============================] - 1s 59us/step - loss: 3716.5726 - mean_absolute_error: 39.0204 - val_loss: 3051.6219 - val_mean_absolute_error: 33.9098\n",
      "Epoch 9/100\n",
      "15632/15632 [==============================] - 1s 61us/step - loss: 3071.5520 - mean_absolute_error: 36.0226 - val_loss: 2524.3215 - val_mean_absolute_error: 31.5336\n",
      "Epoch 10/100\n",
      "15632/15632 [==============================] - 1s 64us/step - loss: 2678.8979 - mean_absolute_error: 34.3003 - val_loss: 2179.0420 - val_mean_absolute_error: 29.8849\n",
      "Epoch 11/100\n",
      "15632/15632 [==============================] - 1s 60us/step - loss: 2429.3874 - mean_absolute_error: 32.9176 - val_loss: 1990.1522 - val_mean_absolute_error: 28.0846\n",
      "Epoch 12/100\n",
      "15632/15632 [==============================] - 1s 69us/step - loss: 2273.0052 - mean_absolute_error: 32.0005 - val_loss: 1818.8772 - val_mean_absolute_error: 26.8449\n",
      "Epoch 13/100\n",
      "15632/15632 [==============================] - 1s 62us/step - loss: 2150.5216 - mean_absolute_error: 31.2418 - val_loss: 1772.7613 - val_mean_absolute_error: 26.6204\n",
      "Epoch 14/100\n",
      "15632/15632 [==============================] - 1s 62us/step - loss: 2086.3243 - mean_absolute_error: 30.5305 - val_loss: 1682.6357 - val_mean_absolute_error: 26.0531\n",
      "Epoch 15/100\n",
      "15632/15632 [==============================] - 1s 63us/step - loss: 2020.8095 - mean_absolute_error: 30.2965 - val_loss: 1613.6968 - val_mean_absolute_error: 25.8676\n",
      "Epoch 16/100\n",
      "15632/15632 [==============================] - 1s 66us/step - loss: 1896.8120 - mean_absolute_error: 29.4200 - val_loss: 1557.0984 - val_mean_absolute_error: 25.2732\n",
      "Epoch 17/100\n",
      "15632/15632 [==============================] - 1s 70us/step - loss: 1904.0148 - mean_absolute_error: 29.5737 - val_loss: 1519.1775 - val_mean_absolute_error: 25.1257\n",
      "Epoch 18/100\n",
      "15632/15632 [==============================] - 1s 64us/step - loss: 1930.1561 - mean_absolute_error: 29.4581 - val_loss: 1444.4474 - val_mean_absolute_error: 24.7156\n",
      "Epoch 19/100\n",
      "15632/15632 [==============================] - 1s 62us/step - loss: 1878.6025 - mean_absolute_error: 29.1310 - val_loss: 1428.8960 - val_mean_absolute_error: 24.6534\n",
      "Epoch 20/100\n",
      "15632/15632 [==============================] - 1s 61us/step - loss: 1842.2823 - mean_absolute_error: 29.0694 - val_loss: 1478.3389 - val_mean_absolute_error: 24.6623\n",
      "Epoch 21/100\n",
      "15632/15632 [==============================] - 1s 65us/step - loss: 1738.7747 - mean_absolute_error: 28.2327 - val_loss: 1442.0980 - val_mean_absolute_error: 24.0544\n",
      "Epoch 22/100\n",
      "15632/15632 [==============================] - 1s 64us/step - loss: 1748.3070 - mean_absolute_error: 28.4794 - val_loss: 1368.8935 - val_mean_absolute_error: 23.7690\n",
      "Epoch 23/100\n",
      "15632/15632 [==============================] - 1s 62us/step - loss: 1761.1895 - mean_absolute_error: 28.1641 - val_loss: 1362.5335 - val_mean_absolute_error: 23.6506\n",
      "Epoch 24/100\n",
      "15632/15632 [==============================] - 1s 61us/step - loss: 1739.4887 - mean_absolute_error: 28.1197 - val_loss: 1370.8163 - val_mean_absolute_error: 24.0362\n",
      "Epoch 25/100\n",
      "15632/15632 [==============================] - 1s 63us/step - loss: 1711.2848 - mean_absolute_error: 27.8041 - val_loss: 1368.7762 - val_mean_absolute_error: 24.1060\n",
      "Epoch 26/100\n",
      "15632/15632 [==============================] - 1s 62us/step - loss: 1664.1836 - mean_absolute_error: 27.5043 - val_loss: 1322.9678 - val_mean_absolute_error: 23.4731\n",
      "Epoch 27/100\n",
      "15632/15632 [==============================] - 1s 66us/step - loss: 1696.2406 - mean_absolute_error: 27.7893 - val_loss: 1346.8500 - val_mean_absolute_error: 23.6322\n",
      "Epoch 28/100\n",
      "15632/15632 [==============================] - 1s 66us/step - loss: 1689.3368 - mean_absolute_error: 27.4487 - val_loss: 1362.1219 - val_mean_absolute_error: 23.8129\n",
      "Epoch 29/100\n",
      "15632/15632 [==============================] - 1s 62us/step - loss: 1624.4651 - mean_absolute_error: 27.0841 - val_loss: 1491.7019 - val_mean_absolute_error: 25.2417\n",
      "Epoch 30/100\n",
      "15632/15632 [==============================] - 1s 62us/step - loss: 1621.0096 - mean_absolute_error: 27.2629 - val_loss: 1295.4584 - val_mean_absolute_error: 23.6858\n",
      "Epoch 31/100\n",
      "15632/15632 [==============================] - 1s 68us/step - loss: 1609.3373 - mean_absolute_error: 26.9568 - val_loss: 1330.6804 - val_mean_absolute_error: 23.7114\n",
      "Epoch 32/100\n",
      "15632/15632 [==============================] - 1s 67us/step - loss: 1621.3034 - mean_absolute_error: 27.0300 - val_loss: 1330.1307 - val_mean_absolute_error: 23.6658\n",
      "Epoch 33/100\n",
      "15632/15632 [==============================] - 1s 68us/step - loss: 1599.3015 - mean_absolute_error: 26.9246 - val_loss: 1317.4134 - val_mean_absolute_error: 23.1718\n",
      "Epoch 34/100\n",
      "15632/15632 [==============================] - 1s 69us/step - loss: 1594.9289 - mean_absolute_error: 26.7090 - val_loss: 1262.4070 - val_mean_absolute_error: 22.8964\n",
      "Epoch 35/100\n",
      "15632/15632 [==============================] - 1s 66us/step - loss: 1593.7387 - mean_absolute_error: 26.7149 - val_loss: 1229.8493 - val_mean_absolute_error: 22.4683\n",
      "Epoch 36/100\n",
      "15632/15632 [==============================] - 1s 68us/step - loss: 1513.6310 - mean_absolute_error: 26.2974 - val_loss: 1241.7577 - val_mean_absolute_error: 22.9387\n",
      "Epoch 37/100\n",
      "15632/15632 [==============================] - 1s 66us/step - loss: 1561.7642 - mean_absolute_error: 26.3655 - val_loss: 1220.0925 - val_mean_absolute_error: 22.7314\n",
      "Epoch 38/100\n",
      "15632/15632 [==============================] - 1s 67us/step - loss: 1573.0808 - mean_absolute_error: 26.4386 - val_loss: 1231.7577 - val_mean_absolute_error: 22.6050\n",
      "Epoch 39/100\n",
      "15632/15632 [==============================] - 1s 67us/step - loss: 1548.7426 - mean_absolute_error: 26.4065 - val_loss: 1290.4140 - val_mean_absolute_error: 23.0540\n",
      "Epoch 40/100\n",
      "15632/15632 [==============================] - 1s 65us/step - loss: 1512.5508 - mean_absolute_error: 26.2507 - val_loss: 1214.6454 - val_mean_absolute_error: 22.6137\n",
      "Epoch 41/100\n",
      "15632/15632 [==============================] - 1s 69us/step - loss: 1480.7168 - mean_absolute_error: 25.7712 - val_loss: 1195.8839 - val_mean_absolute_error: 22.0898\n",
      "Epoch 42/100\n",
      "15632/15632 [==============================] - 1s 74us/step - loss: 1482.4798 - mean_absolute_error: 25.8733 - val_loss: 1238.0335 - val_mean_absolute_error: 22.3538\n",
      "Epoch 43/100\n",
      "15632/15632 [==============================] - 1s 83us/step - loss: 1486.5767 - mean_absolute_error: 25.7566 - val_loss: 1178.4902 - val_mean_absolute_error: 22.1982\n",
      "Epoch 44/100\n",
      "15632/15632 [==============================] - 1s 71us/step - loss: 1532.5353 - mean_absolute_error: 25.9816 - val_loss: 1269.4722 - val_mean_absolute_error: 22.8440\n",
      "Epoch 45/100\n",
      "15632/15632 [==============================] - 1s 68us/step - loss: 1469.9355 - mean_absolute_error: 25.5702 - val_loss: 1231.0838 - val_mean_absolute_error: 22.6887\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15632/15632 [==============================] - 1s 60us/step - loss: 1481.2160 - mean_absolute_error: 25.7458 - val_loss: 1175.2849 - val_mean_absolute_error: 22.1345\n",
      "Epoch 47/100\n",
      "15632/15632 [==============================] - 1s 58us/step - loss: 1441.9111 - mean_absolute_error: 25.5625 - val_loss: 1217.2596 - val_mean_absolute_error: 22.3544\n",
      "Epoch 48/100\n",
      "15632/15632 [==============================] - 1s 60us/step - loss: 1482.4908 - mean_absolute_error: 25.7160 - val_loss: 1183.3028 - val_mean_absolute_error: 21.9111\n",
      "Epoch 49/100\n",
      "15632/15632 [==============================] - 1s 68us/step - loss: 1467.1566 - mean_absolute_error: 25.6102 - val_loss: 1153.8309 - val_mean_absolute_error: 21.7179\n",
      "Epoch 50/100\n",
      "15632/15632 [==============================] - 1s 60us/step - loss: 1455.9423 - mean_absolute_error: 25.5067 - val_loss: 1179.8878 - val_mean_absolute_error: 22.1538\n",
      "Epoch 51/100\n",
      "15632/15632 [==============================] - 1s 60us/step - loss: 1410.5948 - mean_absolute_error: 25.2090 - val_loss: 1164.3418 - val_mean_absolute_error: 22.0996\n",
      "Epoch 52/100\n",
      "15632/15632 [==============================] - 1s 59us/step - loss: 1437.1501 - mean_absolute_error: 25.2544 - val_loss: 1181.7583 - val_mean_absolute_error: 22.1546\n",
      "Epoch 53/100\n",
      "15632/15632 [==============================] - 1s 59us/step - loss: 1442.8266 - mean_absolute_error: 25.3547 - val_loss: 1139.0801 - val_mean_absolute_error: 21.6471\n",
      "Epoch 54/100\n",
      "15632/15632 [==============================] - 1s 60us/step - loss: 1422.0126 - mean_absolute_error: 25.2064 - val_loss: 1150.7676 - val_mean_absolute_error: 21.8768\n",
      "Epoch 55/100\n",
      "15632/15632 [==============================] - 1s 60us/step - loss: 1425.9780 - mean_absolute_error: 25.2047 - val_loss: 1150.6353 - val_mean_absolute_error: 22.0053\n",
      "Epoch 56/100\n",
      "15632/15632 [==============================] - 1s 60us/step - loss: 1412.9555 - mean_absolute_error: 25.1140 - val_loss: 1306.6917 - val_mean_absolute_error: 23.2982\n",
      "Epoch 57/100\n",
      "15632/15632 [==============================] - 2s 127us/step - loss: 1370.4999 - mean_absolute_error: 24.7526 - val_loss: 1150.8477 - val_mean_absolute_error: 21.7747\n",
      "Epoch 58/100\n",
      "15632/15632 [==============================] - 1s 59us/step - loss: 1383.3584 - mean_absolute_error: 24.8969 - val_loss: 1145.3317 - val_mean_absolute_error: 22.0839\n",
      "Epoch 59/100\n",
      "15632/15632 [==============================] - 1s 61us/step - loss: 1378.0154 - mean_absolute_error: 24.7947 - val_loss: 1160.8508 - val_mean_absolute_error: 22.0055\n",
      "Epoch 60/100\n",
      "15632/15632 [==============================] - 1s 59us/step - loss: 1398.8958 - mean_absolute_error: 24.9539 - val_loss: 1171.5153 - val_mean_absolute_error: 22.1143\n",
      "Epoch 61/100\n",
      "15632/15632 [==============================] - 1s 62us/step - loss: 1358.6148 - mean_absolute_error: 24.7490 - val_loss: 1124.8510 - val_mean_absolute_error: 21.6836\n",
      "Epoch 62/100\n",
      "15632/15632 [==============================] - 1s 62us/step - loss: 1378.8185 - mean_absolute_error: 24.8011 - val_loss: 1106.3949 - val_mean_absolute_error: 21.5742\n",
      "Epoch 63/100\n",
      "15632/15632 [==============================] - 1s 63us/step - loss: 1333.8045 - mean_absolute_error: 24.5631 - val_loss: 1125.6194 - val_mean_absolute_error: 21.8221\n",
      "Epoch 64/100\n",
      "15632/15632 [==============================] - 1s 62us/step - loss: 1376.0263 - mean_absolute_error: 24.9002 - val_loss: 1122.9944 - val_mean_absolute_error: 21.8747\n",
      "Epoch 65/100\n",
      "15632/15632 [==============================] - 1s 61us/step - loss: 1371.0729 - mean_absolute_error: 24.6008 - val_loss: 1160.9413 - val_mean_absolute_error: 21.8026\n",
      "Epoch 66/100\n",
      "15632/15632 [==============================] - 1s 62us/step - loss: 1358.3006 - mean_absolute_error: 24.7142 - val_loss: 1097.1711 - val_mean_absolute_error: 21.4247\n",
      "Epoch 67/100\n",
      "15632/15632 [==============================] - 1s 65us/step - loss: 1338.1758 - mean_absolute_error: 24.5664 - val_loss: 1093.1124 - val_mean_absolute_error: 21.2647\n",
      "Epoch 68/100\n",
      "15632/15632 [==============================] - 1s 62us/step - loss: 1324.3928 - mean_absolute_error: 24.3403 - val_loss: 1144.2150 - val_mean_absolute_error: 22.1025\n",
      "Epoch 69/100\n",
      "15632/15632 [==============================] - 1s 67us/step - loss: 1339.5100 - mean_absolute_error: 24.4729 - val_loss: 1066.1176 - val_mean_absolute_error: 21.6779\n",
      "Epoch 70/100\n",
      "15632/15632 [==============================] - 1s 65us/step - loss: 1332.3238 - mean_absolute_error: 24.4709 - val_loss: 1104.5850 - val_mean_absolute_error: 21.5724\n",
      "Epoch 71/100\n",
      "15632/15632 [==============================] - 1s 69us/step - loss: 1323.9225 - mean_absolute_error: 24.3376 - val_loss: 1067.0081 - val_mean_absolute_error: 21.4365\n",
      "Epoch 72/100\n",
      "15632/15632 [==============================] - 1s 67us/step - loss: 1311.3541 - mean_absolute_error: 24.3624 - val_loss: 1072.3223 - val_mean_absolute_error: 21.3147\n",
      "Epoch 73/100\n",
      "15632/15632 [==============================] - 1s 63us/step - loss: 1305.3594 - mean_absolute_error: 24.2479 - val_loss: 1112.9750 - val_mean_absolute_error: 21.3496\n",
      "Epoch 74/100\n",
      "15632/15632 [==============================] - 1s 63us/step - loss: 1313.2548 - mean_absolute_error: 24.1669 - val_loss: 1094.1001 - val_mean_absolute_error: 21.4761\n",
      "Epoch 75/100\n",
      "15632/15632 [==============================] - 1s 64us/step - loss: 1314.8535 - mean_absolute_error: 24.2918 - val_loss: 1053.9420 - val_mean_absolute_error: 21.1507\n",
      "Epoch 76/100\n",
      "15632/15632 [==============================] - 1s 65us/step - loss: 1294.9499 - mean_absolute_error: 24.1063 - val_loss: 1123.8984 - val_mean_absolute_error: 21.9504\n",
      "Epoch 77/100\n",
      "15632/15632 [==============================] - 1s 63us/step - loss: 1331.8800 - mean_absolute_error: 24.4233 - val_loss: 1099.4640 - val_mean_absolute_error: 21.4646\n",
      "Epoch 78/100\n",
      "15632/15632 [==============================] - 1s 67us/step - loss: 1320.9269 - mean_absolute_error: 24.3281 - val_loss: 1146.8679 - val_mean_absolute_error: 21.7431\n",
      "Epoch 79/100\n",
      "15632/15632 [==============================] - 1s 64us/step - loss: 1312.2651 - mean_absolute_error: 24.1338 - val_loss: 1100.2521 - val_mean_absolute_error: 21.6993\n",
      "Epoch 80/100\n",
      "15632/15632 [==============================] - 1s 68us/step - loss: 1311.4243 - mean_absolute_error: 24.1291 - val_loss: 1048.8422 - val_mean_absolute_error: 21.1024\n",
      "Epoch 81/100\n",
      "15632/15632 [==============================] - 1s 63us/step - loss: 1285.9235 - mean_absolute_error: 24.0646 - val_loss: 1078.9908 - val_mean_absolute_error: 21.2894\n",
      "Epoch 82/100\n",
      "15632/15632 [==============================] - 1s 64us/step - loss: 1269.2546 - mean_absolute_error: 23.9959 - val_loss: 1045.2072 - val_mean_absolute_error: 21.2263\n",
      "Epoch 83/100\n",
      "15632/15632 [==============================] - 1s 65us/step - loss: 1273.0196 - mean_absolute_error: 23.9385 - val_loss: 1211.6675 - val_mean_absolute_error: 22.4504\n",
      "Epoch 84/100\n",
      "15632/15632 [==============================] - 1s 65us/step - loss: 1262.7531 - mean_absolute_error: 23.7952 - val_loss: 1076.3266 - val_mean_absolute_error: 21.3368\n",
      "Epoch 85/100\n",
      "15632/15632 [==============================] - 1s 66us/step - loss: 1271.9784 - mean_absolute_error: 23.9810 - val_loss: 1089.1755 - val_mean_absolute_error: 21.2883\n",
      "Epoch 86/100\n",
      "15632/15632 [==============================] - 1s 66us/step - loss: 1254.9491 - mean_absolute_error: 23.8054 - val_loss: 1047.0404 - val_mean_absolute_error: 20.9416\n",
      "Epoch 87/100\n",
      "15632/15632 [==============================] - 1s 67us/step - loss: 1239.7875 - mean_absolute_error: 23.7859 - val_loss: 1028.4748 - val_mean_absolute_error: 21.0714\n",
      "Epoch 88/100\n",
      "15632/15632 [==============================] - 1s 71us/step - loss: 1254.7908 - mean_absolute_error: 23.6954 - val_loss: 1095.7504 - val_mean_absolute_error: 21.1608\n",
      "Epoch 89/100\n",
      "15632/15632 [==============================] - 1s 66us/step - loss: 1247.9245 - mean_absolute_error: 23.7049 - val_loss: 1060.7205 - val_mean_absolute_error: 21.5390\n",
      "Epoch 90/100\n",
      "15632/15632 [==============================] - 1s 70us/step - loss: 1266.4904 - mean_absolute_error: 24.0241 - val_loss: 1051.6525 - val_mean_absolute_error: 20.9328\n",
      "Epoch 91/100\n",
      "15632/15632 [==============================] - 1s 69us/step - loss: 1256.7910 - mean_absolute_error: 23.9237 - val_loss: 1046.2253 - val_mean_absolute_error: 21.1100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/100\n",
      "15632/15632 [==============================] - 1s 59us/step - loss: 1262.3557 - mean_absolute_error: 23.8426 - val_loss: 1074.9866 - val_mean_absolute_error: 21.2275\n",
      "Epoch 93/100\n",
      "15632/15632 [==============================] - 1s 60us/step - loss: 1239.0941 - mean_absolute_error: 23.7080 - val_loss: 1064.5823 - val_mean_absolute_error: 21.1540\n",
      "Epoch 94/100\n",
      "15632/15632 [==============================] - 1s 59us/step - loss: 1229.2980 - mean_absolute_error: 23.6659 - val_loss: 1051.8321 - val_mean_absolute_error: 21.1227\n",
      "Epoch 95/100\n",
      "15632/15632 [==============================] - 1s 62us/step - loss: 1223.2396 - mean_absolute_error: 23.5965 - val_loss: 1053.0662 - val_mean_absolute_error: 20.9806\n",
      "Epoch 96/100\n",
      "15632/15632 [==============================] - 1s 61us/step - loss: 1248.2370 - mean_absolute_error: 23.8179 - val_loss: 1189.9852 - val_mean_absolute_error: 22.2740\n",
      "Epoch 97/100\n",
      "15632/15632 [==============================] - 1s 61us/step - loss: 1235.7148 - mean_absolute_error: 23.6617 - val_loss: 1093.9655 - val_mean_absolute_error: 21.3412\n",
      "Epoch 98/100\n",
      "15632/15632 [==============================] - 1s 58us/step - loss: 1234.3533 - mean_absolute_error: 23.7066 - val_loss: 1046.6833 - val_mean_absolute_error: 20.8860\n",
      "Epoch 99/100\n",
      "15632/15632 [==============================] - 1s 61us/step - loss: 1222.2042 - mean_absolute_error: 23.6611 - val_loss: 1068.0983 - val_mean_absolute_error: 21.3537\n",
      "Epoch 100/100\n",
      "15632/15632 [==============================] - 1s 60us/step - loss: 1217.8175 - mean_absolute_error: 23.4958 - val_loss: 1072.1318 - val_mean_absolute_error: 21.1403\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f510a086dd8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train,\n",
    "          batch_size = 128, epochs = 100, verbose=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the models\n",
    "\n",
    "Measure mean squared error and mean absolute error evaluation metrics on both train and test data sets. Compute the mean and standard deviation of the target values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test mean: 196.9222797927461, std: 187.62398319999474\n",
      "Test Root mean squared error: 32.74\n",
      "Test Mean absolute error: 21.14\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print (\"Test mean: {}, std: {}\".format(np.mean(y_test), np.std(y_test)))\n",
    "print(\"Test Root mean squared error: {:.2f}\".format(np.sqrt(mean_squared_error(y_test, y_pred))))\n",
    "print(\"Test Mean absolute error: {:.2f}\".format(mean_absolute_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Root mean squared error: 28.82\n",
      "Train Mean absolute error: 19.14\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_train)\n",
    "print(\"Train Root mean squared error: %.2f\"\n",
    "      % np.sqrt(mean_squared_error(y_train, y_pred)))\n",
    "print(\"Train Mean absolute error: %.2f\"\n",
    "      % mean_absolute_error(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
